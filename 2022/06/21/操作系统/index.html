<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="操作系统硬件结构冯诺依曼模型：运算器、控制器、存储器、输入设备、输出设备   运算器和控制器在CPU里，存储器就是内存，存储单元和输入输出设备打交道需要总线。   内存程序和数据都是存储在内存，存储的区域是线性的。 计算机最小的存储单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/2022/06/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="操作系统硬件结构冯诺依曼模型：运算器、控制器、存储器、输入设备、输出设备   运算器和控制器在CPU里，存储器就是内存，存储单元和输入输出设备打交道需要总线。   内存程序和数据都是存储在内存，存储的区域是线性的。 计算机最小的存储单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2022-06-21T07:10:43.360Z">
<meta property="article:modified_time" content="2022-06-10T16:23:57.597Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2022/06/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hexo</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/21/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-06-21 15:10:43" itemprop="dateCreated datePublished" datetime="2022-06-21T15:10:43+08:00">2022-06-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-06-11 00:23:57" itemprop="dateModified" datetime="2022-06-11T00:23:57+08:00">2022-06-11</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><h2 id="硬件结构"><a href="#硬件结构" class="headerlink" title="硬件结构"></a>硬件结构</h2><p>冯诺依曼模型：<strong>运算器、控制器、存储器、输入设备、输出设备</strong></p>


<p>运算器和控制器在CPU里，存储器就是内存，存储单元和输入输出设备打交道需要总线。</p>


<h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>程序和数据都是存储在内存，<strong>存储的区域是线性的</strong>。</p>
<p><strong>计算机最小的存储单位是字节（byte）</strong>，1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。<strong>内存地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1</strong>，这种结构好似我们程序里的数组，所以<strong>内存的读写任何一个数据的速度都是一样的</strong>。</p>
<h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p>32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据：</p>
<ul>
<li>32 位 CPU 一次可以计算 4 个字节；</li>
<li>64 位 CPU 一次可以计算 8 个字节； 32位和64位称为CPU的位宽</li>
</ul>
<p>如果是 8 位的 CPU，那么一次只能计算 1 个字节 <code>0~255</code> （2<em>8-1）范围内的数值，这样就无法一次完成计算 10000 * 500，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 <code>4294967295</code>（2</em>32-1）。</p>
<p>CPU 内部还有一些组件，常见的有<strong>寄存器、控制单元和逻辑运算单元</strong>等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。</p>
<p><strong>寄存器主要作用是存储计算时的数据，为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。</strong></p>
<p>常见的寄存器种类：</p>
<ul>
<li>通用寄存器，<strong>用来存放需要进行运算的数据</strong>，比如需要进行加和运算的两个数据。</li>
<li>程序计数器，<strong>用来存储 CPU 要执行下一条指令「所在的内存地址」</strong>，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。</li>
<li>指令寄存器，<strong>用来存放程序计数器指向的指令，也就是指令本身</strong>，指令被执行完成之前，指令都存储在这里。</li>
</ul>
<h3 id="总线"><a href="#总线" class="headerlink" title="总线"></a>总线</h3><p>总线用于 <strong>CPU 和内存以及其他设备之间的通信</strong></p>
<ul>
<li>地址总线，用于指定 CPU 将要操作的内存地址；</li>
<li>数据总线，用于读写内存的数据；</li>
<li>控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；</li>
</ul>
<p>当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线：</p>
<ul>
<li>首先要通过「地址总线」来指定内存的地址；</li>
<li>然后通过「控制总线」控制是读或写命令；</li>
<li>最后通过「数据总线」来传输数据；</li>
</ul>
<h3 id="线路位宽和CPU位宽"><a href="#线路位宽和CPU位宽" class="headerlink" title="线路位宽和CPU位宽"></a>线路位宽和CPU位宽</h3><p>数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，高电压则表示 1。</p>
<p>如果构造了高低高这样的信号，其实就是 101 二进制数据，十进制则表示 5，如果只有一条线路，就意味着每次只能传递 1 bit 的数据，即 0 或 1，那么传输 101 这个数据，就需要 3 次才能传输完成，效率非常低。</p>
<p>这样一位一位传输的方式，称为串行，下一个 bit 必须等待上一个 bit 传输完成才能进行传输。当然，想一次多传一些数据，增加线路即可，这时数据就可以并行传输。</p>
<p><strong>为了避免低效率的串行传输的方式，线路的位宽最好一次就能访问到所有的内存地址。</strong></p>
<p>CPU 要想操作的内存地址就需要地址总线：</p>
<ul>
<li>如果地址总线只有 1 条，那每次只能表示 「0 或 1」这两种地址，所以 CPU 能操作的内存地址最大数量为 2（2^1）个（注意，不要理解成同时能操作 2 个内存地址）；</li>
<li>如果地址总线有 2 条，那么能表示 00、01、10、11 这四种地址，所以 CPU 能操作的内存地址最大数量为 4（2^2）个。</li>
</ul>
<p>那么，<strong>想要 CPU 操作 4G 大的内存，那么就需要 32 条地址总线，因为 <code>2 ^ 32 = 4G</code>(字节)。</strong></p>
<p>知道了线路位宽的意义后，我们再来看看 CPU 位宽。</p>
<p><strong>CPU 的位宽最好不要小于线路位宽</strong>，比如 32 位 CPU 控制 40 位宽的地址总线和数据总线的话，工作起来就会非常复杂且麻烦，所以 32 位的 CPU 最好和 32 位宽的线路搭配，因为 32 位 CPU 一次最多只能操作 32 位宽的地址总线和数据总线。</p>
<p>如果用 32 位 CPU 去加和两个 64 位大小的数字，就需要把这 2 个 64 位的数字分成 2 个低位 32 位数字和 2 个高位 32 位数字来计算，先加个两个低位的 32 位数字，算出进位，然后加和两个高位的 32 位数字，最后再加上进位，就能算出结果了，可以发现 <strong>32 位 CPU 并不能一次性计算出加和两个 64 位数字的结果。</strong></p>
<p>对于 <strong>64 位 CPU 就可以一次性算出加和两个 64 位数字的结果</strong>，因为 64 位 CPU 可以一次读入 64 位的数字，并且 64 位 CPU 内部的逻辑运算单元也支持 64 位数字的计算。</p>
<p>但是并不代表 64 位 CPU 性能比 32 位 CPU 高很多，很少应用需要算超过 32 位的数字，所以<strong>如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来</strong>。</p>
<p>另外，<strong>32 位 CPU 最大只能操作 4GB 内存，就算你装了 8 GB 内存条，也没用</strong>。而 64 位 CPU 寻址范围则很大，理论最大的寻址空间为 <code>2^64</code>（16GB）。</p>
<h3 id="程序执行的基本过程"><a href="#程序执行的基本过程" class="headerlink" title="程序执行的基本过程"></a>程序执行的基本过程</h3><p>程序实际上是一条一条指令，所以程序的运行过程就是把每一条指令一步一步的执行起来，负责执行指令的就是 CPU 了。</p>


<ul>
<li>第一步，CPU 读取「程序计数器」中指令的内存地址，然后 CPU 的「控制单元」操作「地址总线」指定需要访问的内存地址，接着通知内存设备准备数据，数据准备好后通过「数据总线」将指令数据传给 CPU，CPU 收到内存传来的数据后，将这个指令数据存入到「指令寄存器」。</li>
<li>第二步，CPU 分析「指令寄存器」中的指令，确定指令的类型和参数，如果是计算类型的指令，就把指令交给「逻辑运算单元」运算；如果是存储类型的指令，则交由「控制单元」执行；</li>
<li>第三步，CPU 执行完指令后，「程序计数器」的值自增，表示指向下一条指令。<strong>自增的大小由 CPU 的位宽决定，比如 32 位的 CPU，指令是 4 个字节，需要 4 个内存地址存放，因此「程序计数器」的值会自增 4；</strong></li>
</ul>
<p>简单总结一下就是，一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。</p>
<p>CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 <strong>CPU 的指令周期</strong>。</p>
<h3 id="a-x3D-1-2执行的具体过程"><a href="#a-x3D-1-2执行的具体过程" class="headerlink" title="a &#x3D; 1+2执行的具体过程"></a>a &#x3D; 1+2执行的具体过程</h3><p>CPU不认识a&#x3D;1+2</p>
<p>要想这段程序能跑起来，还需要把整个程序翻译成<strong>汇编语言</strong>的程序，这个过程称为编译成汇编代码。</p>
<p>针对汇编代码，我们还需要用汇编器翻译成机器码，机器码由 0 和 1 组成，这一条条机器码，就是一条条的<strong>计算机指令</strong>，这个才是 CPU 能够真正认识的东西。</p>
<p>下面来看看 <code>a = 1 + 2</code> 在 32 位 CPU 的执行过程。</p>
<p>程序编译过程中，编译器通过分析代码，发现 1 和 2 是数据，于是程序运行时，内存会有个专门的区域来存放这些数据，这个区域就是「数据段」。如下图，数据 1 和 2 的区域位置：</p>
<ul>
<li>数据 1 被存放到 0x100 位置；</li>
<li>数据 2 被存放到 0x104 位置；（发现在地址区都是以4为间隔，指令在32位CPU是4个字节，需要4个内存地址存放）</li>
</ul>
<p>注意，数据和指令是分开区域存放的，存放指令区域的地方称为「正文段」。</p>


<p>编译器会把 <code>a = 1 + 2</code> 翻译成 4 条指令，存放到正文段中。如图，这 4 条指令被存放到了 0x200 ~ 0x20c 的区域中：</p>
<ul>
<li>0x200 的内容是 <code>load</code> 指令将 0x100 地址中的数据 1 装入到寄存器 <code>R0</code>；</li>
<li>0x204 的内容是 <code>load</code> 指令将 0x104 地址中的数据 2 装入到寄存器 <code>R1</code>；</li>
<li>0x208 的内容是 <code>add</code> 指令将寄存器 <code>R0</code> 和 <code>R1</code> 的数据相加，并把结果存放到寄存器 <code>R2</code>；</li>
<li>0x20c 的内容是 <code>store</code> 指令将寄存器 <code>R2</code> 中的数据存回数据段中的 0x108 地址中，这个地址也就是变量 <code>a</code> 内存中的地址；</li>
</ul>
<p>编译完成后，具体执行程序的时候，程序计数器会被设置为 0x200 地址，然后依次执行这 4 条指令。</p>
<p><strong>上面的例子中（指令存放和数据存放分开理解，占的字节也不一样），由于是在 32 位 CPU 执行的，因此一条指令是占 32 位大小，所以你会发现每条指令间隔 4 个字节。</strong></p>
<p>而<strong>数据的大小是根据你在程序中指定的变量类型，比如 <code>int</code> 类型的数据则占 4 个字节，<code>char</code> 类型的数据则占 1 个字节。</strong></p>
<h3 id="指令…"><a href="#指令…" class="headerlink" title="#指令…"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/1_hardware/how_cpu_run.html#%E6%8C%87%E4%BB%A4">#</a>指令…</h3><h3 id="指令执行速度"><a href="#指令执行速度" class="headerlink" title="指令执行速度"></a>指令执行速度</h3><p>CPU 的硬件参数都会有 <code>GHz</code> 这个参数，比如<strong>一个 1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为时钟周期。</strong></p>
<p><strong>时钟周期时间 &#x3D; 1&#x2F;时钟频率&#x3D; 1&#x2F;CPU主频</strong>，一个 1 GHz 的 CPU时钟周期时间为1&#x2F;1G 。</p>
<p>在一个时钟周期内，CPU 仅能完成一个最基本的动作，<strong>时钟频率越高，时钟周期就越短，工作速度也就越快。</strong></p>
<p>大多数指令不能在一个时钟周期完成，通常需要若干个时钟周期。加法和乘法都对应着一条 CPU 指令，但是乘法需要的时钟周期就要比加法多。</p>
<h3 id="程序的CPU执行时间"><a href="#程序的CPU执行时间" class="headerlink" title="程序的CPU执行时间"></a>程序的CPU执行时间</h3><p>执行时间 &#x3D; 指令数 × 每条指令的平均时钟周期数 × 时钟周期时间</p>
<p>要程序跑得快，优化以上三者</p>
<h3 id="几个问题"><a href="#几个问题" class="headerlink" title="几个问题"></a>几个问题</h3><p>64 位相比 32 位 CPU 的优势在哪吗？64 位 CPU 的计算性能一定比 32 位 CPU 高很多吗？</p>
<p>64 位相比 32 位 CPU 的优势主要体现在两个方面：</p>
<ul>
<li>64 位 CPU 可以一次计算超过 32 位的数字，而 32 位 CPU 如果要计算超过 32 位的数字，要分多步骤进行计算，效率就没那么高，但是大部分应用程序很少会计算那么大的数字，所以<strong>只有运算大数字的时候，64 位 CPU 的优势才能体现出来，否则和 32 位 CPU 的计算性能相差不大</strong>。</li>
<li>64 位 CPU 可以<strong>寻址更大的内存空间</strong>，32 位 CPU 最大的寻址地址是 4G，即使你加了 8G 大小的内存，也还是只能寻址到 4G，而 64 位 CPU 最大寻址地址是 <code>2^64</code>，远超于 32 位 CPU 最大寻址地址的 <code>2^32</code>。</li>
</ul>
<p>软件的 32 位和 64 位之间的区别？32 位的操作系统可以运行在 64 位的电脑上吗？64 位的操作系统可以运行在 32 位的电脑上吗？如果不行，原因是什么？</p>
<p><strong>64 位和 32 位软件，实际上代表指令是 64 位还是 32 位的：</strong></p>
<ul>
<li>如果 32 位指令在 64 位机器上执行，需要一套兼容机制，就可以做到兼容运行了。但是<strong>如果 64 位指令在 32 位机器上执行，就比较困难了，因为 32 位的寄存器存不下 64 位的指令</strong>；</li>
<li>操作系统其实也是一种程序，我们也会看到操作系统会分成 32 位操作系统、64 位操作系统，其代表意义就是操作系统中程序的指令是多少位，比如 64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。</li>
</ul>
<p>总之，<strong>硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽</strong>。</p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><h3 id="存储器"><a href="#存储器" class="headerlink" title="存储器"></a>存储器</h3><h4 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h4><p>寄存器是最靠近CPU控制单元和逻辑计算单元的存储器，每个寄存器可以用来存储一定的字节的数据。</p>
<ul>
<li>32 位 CPU 中大多数寄存器可以存储 <code>4</code> 个字节；</li>
<li>64 位 CPU 中大多数寄存器可以存储 <code>8</code> 个字节。</li>
</ul>
<p>CPU 处理一条指令的时候，除了读写寄存器，还需要解码指令、控制指令执行和计算。如果寄存器的速度太慢，则会拉长指令的处理周期，从而给用户的感觉，就是电脑「很慢」。</p>
<h4 id="CPU-Cache"><a href="#CPU-Cache" class="headerlink" title="CPU Cache"></a>CPU Cache</h4><p>CPU Cache 用的是一种叫 <strong>SRAM（Static Random-Access Memory，静态随机存储器）</strong> 的芯片。之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。</p>
<p> <strong>L1 高速缓存每个 CPU 核心都有</strong>，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成<strong>指令缓存</strong>和<strong>数据缓存</strong>。</p>
<p>L2 高速缓存<strong>每个 CPU 核心都有</strong>，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU 核心 更远，它大小比 L1 高速缓存更大。</p>
<p><strong>L3 高速缓存通常是多个 CPU 核心共用的</strong>，位置比 L2 高速缓存距离 CPU 核心 更远，大小也会更大些，通常大小在几 MB 到几十 MB 不等。</p>
<h4 id="内存-1"><a href="#内存-1" class="headerlink" title="内存"></a>内存</h4><p>内存用的芯片使用的是一种叫作 <strong>DRAM （Dynamic Random Access Memory，动态随机存取存储器）</strong> 的芯片。</p>
<h4 id="SSD-x2F-HDD-硬盘"><a href="#SSD-x2F-HDD-硬盘" class="headerlink" title="SSD&#x2F;HDD 硬盘"></a>SSD&#x2F;HDD 硬盘</h4><p>SSD（<em>Solid-state disk</em>） 就是我们常说的固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。</p>
<h4 id="存储器层次关系"><a href="#存储器层次关系" class="headerlink" title="存储器层次关系"></a>存储器层次关系</h4>

<p><strong>每个存储器只和相邻的一层存储器设备打交道（</strong>CPU 并不会直接和每一种存储器设备直接打交道，而是每一种存储器设备只和它相邻的存储器设备打交道。比如，CPU Cache 的数据是从内存加载过来的，写回数据的时候也只写回到内存，CPU Cache 不会直接把数据写到硬盘，也不会直接从硬盘加载数据，而是先加载到内存，再从内存加载到 CPU Cache 中<strong>），并且存储设备为了追求更快的速度，所需的材料成本必然也是更高，也正因为成本太高，所以 CPU 内部的寄存器、L1\L2\L3 Cache 只好用较小的容量，相反内存、硬盘则可用更大的容量，这就是存储器层次结构</strong>。</p>
<p>存储层次结构也形成了<strong>缓存</strong>体系</p>
<p>下图为CPU访问内存中某数据的流程：</p>




<h3 id="如何写出让CPU跑的更快的代码"><a href="#如何写出让CPU跑的更快的代码" class="headerlink" title="如何写出让CPU跑的更快的代码"></a>如何写出让CPU跑的更快的代码</h3><p>代码都是由 CPU 跑起来的，CPU 内部嵌入了 CPU Cache（高速缓存），它的存储容量很小，但是离 CPU 核心很近，所以缓存的读写速度是极快的，如果 CPU 运算时直接从 CPU Cache 而不是从内存读取数据的话，运算速度就会很快。</p>
<p>程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。</p>
<h3 id="CPU-Cache的数据结构和读取过程"><a href="#CPU-Cache的数据结构和读取过程" class="headerlink" title="CPU Cache的数据结构和读取过程"></a>CPU Cache的数据结构和读取过程</h3><p>CPU Cache 的数据是从内存中读取过来的，它是以一小块一小块读取数据的（<strong>Cache Line（缓存块），CPU Line 是 CPU 从内存读取数据到 Cache 的单位</strong>），而不是按照单个数组元素来读取数据的。。</p>
<p>如果说服务器的L1 Cache Line 大小为64字节，意味着 <strong>L1 Cache 一次载入数据的大小是 64 字节</strong>（注意是数据大小，与数据类型有关了）。</p>
<p>有一个 <code>int array[100]</code> 的数组，当载入 <code>array[0]</code> 时，由于这个数组元素的大小在内存只占 4 字节，不足 64 字节，CPU 就会<strong>顺序加载</strong>数组元素到 <code>array[15]</code>，意味着 <code>array[0]~array[15]</code> 数组元素都会被缓存在 CPU Cache 中了，因此当下次访问这些数组元素时，会直接从 CPU Cache 读取，而不用再从内存中读取，大大提高了 CPU 读取数据的性能。</p>
<p><strong>事实上，CPU 读取数据的时候，无论数据是否存放到 Cache 中，CPU 都是先访问 Cache，只有当 Cache 中找不到数据时，才会去访问内存，并把内存中的数据读入到 Cache 中，CPU 再从 CPU Cache 读取数据。</strong></p>


<p>跟我们使用「内存作为硬盘的缓存」的逻辑是一样的，如果内存有缓存的数据，则直接返回，否则要访问龟速一般的硬盘。</p>
<p>那 CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢？…</p>
<h3 id="回到如何写出跑的更快的代码-x2F-如何写出-CPU-缓存命中率高的代码？"><a href="#回到如何写出跑的更快的代码-x2F-如何写出-CPU-缓存命中率高的代码？" class="headerlink" title="回到如何写出跑的更快的代码&#x2F;如何写出 CPU 缓存命中率高的代码？"></a>回到如何写出跑的更快的代码&#x2F;如何写出 CPU 缓存命中率高的代码？</h3><p>访问的数据在 CPU Cache 中的话，意味着<strong>缓存命中</strong>，缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快。</p>
<p> L1 Cache 通常分为「数据缓存」和「指令缓存」，这是因为 CPU 会分别处理数据和指令，比如 <code>1+1=2</code> 这个运算，<code>+</code> 就是指令，会被放在「指令缓存」中，而输入数字 <code>1</code> 则会被放在「数据缓存」里。<strong>分开来看「数据缓存」和「指令缓存」的缓存命中率</strong></p>
<h4 id="①如何提升数据缓存的命中率？"><a href="#①如何提升数据缓存的命中率？" class="headerlink" title="①如何提升数据缓存的命中率？"></a>①如何提升数据缓存的命中率？</h4>

<p>形式一 <code>array[i][j]</code> 执行时间比形式二 <code>array[j][i]</code> 快好几倍。</p>
<p>因为二维数组 <code>array</code> 所占用的内存是连续的，比如长度 <code>N</code> 的值是 <code>2</code> 的话，那么内存中的数组元素的布局顺序是这样的：</p>


<p><strong>形式一用 <code>array[i][j]</code> 访问数组元素的顺序，正是和内存中数组元素存放的顺序一致（按物理内存分布访问）</strong>。当 CPU 访问 <code>array[0][0]</code> 时，由于该数据不在 Cache 中，<strong>于是会「顺序」把跟随其后的 3 个元素从内存中加载到 CPU Cache，这样当 CPU 访问后面的 3 个数组元素时，就能在 CPU Cache 中成功地找到数据，这意味着缓存命中率很高，缓存命中的数据不需要访问内存</strong>，这便大大提高了代码的性能。<strong>（如果Cache Line 大小为64字节，其实会从array00存到array0 15）</strong></p>
<p>形式二的访问是跳跃式的，如果 N 的数值很大，那么操作 <code>array[j][i]</code> 时，是没办法把 <code>array[j+1][i]</code> 也读入到 CPU Cache 中的，既然 <code>array[j+1][i]</code> 没有读取到 CPU Cache，那么就需要从内存读取该数据元素了。</p>
<h4 id="②如何提升指令缓存的命中率？"><a href="#②如何提升指令缓存的命中率？" class="headerlink" title="②如何提升指令缓存的命中率？"></a>②如何提升指令缓存的命中率？</h4><p>一个随机数数组</p>


<p>先遍历后排序快还是先排序后遍历快？</p>
<p>在回答这个问题之前，我们先了解 CPU 的<strong>分支预测器</strong>。对于 if 条件语句，意味着此时至少可以选择跳转到两段不同的指令执行，也就是 if 还是 else 中的指令。<strong>如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快</strong>。</p>
<p><strong>当数组中的元素是随机的，分支预测就无法有效工作，而当数组元素都是是顺序的，分支预测器会动态地根据历史命中数据对未来进行预测，这样命中率就会很高。</strong></p>
<p>故先排序后遍历更快</p>
<h4 id="③提升多核CPU缓存命中率"><a href="#③提升多核CPU缓存命中率" class="headerlink" title="③提升多核CPU缓存命中率"></a>③提升多核CPU缓存命中率</h4><p>现代 CPU 都是多核心的，线程可能在不同 CPU 核心来回切换执行，这对 CPU Cache 不利，因为 L1 和 L2 Cache 都是每个核心独有的，<strong>如果一个线程在不同核心来回切换，各个核心的缓存命中率就会受到影响</strong>，相反如果线程都在同一个核心上执行，那么其数据的 L1 和 L2 Cache 的缓存命中率可以得到有效提高。</p>
<p>当有多个同时执行「计算密集型」的线程，可以把<strong>线程绑定在某一个 CPU 核心上</strong>。在 Linux 上提供了 <code>sched_setaffinity</code> 方法，来实现将线程绑定到某个 CPU 核心这一功能。</p>
<h3 id="CPU缓存一致性…"><a href="#CPU缓存一致性…" class="headerlink" title="#CPU缓存一致性…"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/1_hardware/cpu_mesi.html#_2-4-cpu-%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7">#</a>CPU缓存一致性…</h3><h3 id="CPU如何执行任务的"><a href="#CPU如何执行任务的" class="headerlink" title="CPU如何执行任务的"></a>CPU如何执行任务的</h3><h4 id="CPU如何读写数据"><a href="#CPU如何读写数据" class="headerlink" title="CPU如何读写数据"></a>CPU如何读写数据</h4>

<p>在我们不使用数组，而是使用单独的变量的时候，则会有 Cache 伪共享的问题，Cache 伪共享问题上是一个性能杀手。</p>
<h5 id="伪共享"><a href="#伪共享" class="headerlink" title="伪共享"></a>伪共享</h5><p>现在假设有一个双核心的 CPU，这两个 CPU 核心并行运行着两个不同的线程，它们同时从内存中读取两个不同的数据，分别是类型为 <code>long</code> 的变量 A 和 B，这个两个数据的地址在物理内存上是<strong>连续</strong>的，如果 Cahce Line 的大小是 64 字节，并且变量 A 在 Cahce Line 的开头位置，那么这两个数据是位于<strong>同一个 Cache Line 中</strong>，又因为 CPU Line 是 CPU 从内存读取数据到 Cache 的单位，所以这两个数据会被同时读入到了两个 CPU 核心中各自 Cache 中。</p>


<p>如果这两个不同核心的线程分别修改不同的数据，比如 1 号 CPU 核心的线程只修改了 变量 A，或 2 号 CPU 核心的线程的线程只修改了变量 B，会发生什么呢？</p>
<p>①. 最开始变量 A 和 B 都还不在 Cache 里面，假设 1 号核心绑定了线程 A，2 号核心绑定了线程 B，线程 A 只会读写变量 A，线程 B 只会读写变量 B。</p>


<p>②. 1 号核心读取变量 A，由于 CPU 从内存读取数据到 Cache 的单位是 Cache Line，也正好变量 A 和 变量 B 的数据归属于同一个 Cache Line，所以 A 和 B 的数据都会被加载到 Cache，并将此 Cache Line 标记为「独占」状态。</p>








<p>可以发现如果 1 号和 2 号 CPU 核心这样持续交替的分别修改变量 A 和 B，就会重复 ④ 和 ⑤ 这两个步骤，Cache 并没有起到缓存的效果，虽然变量 A 和 B 之间其实并没有任何的关系，但是因为同时归属于一个 Cache Line ，这个 Cache Line 中的任意数据被修改后，都会相互影响，从而出现 ④ 和 ⑤ 这两个步骤。因此，这种因为多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象称为<strong>伪共享（False Sharing）</strong>。</p>
<p>简述：对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，否则就会出现为伪共享的问题。</p>
<h5 id="避免伪共享"><a href="#避免伪共享" class="headerlink" title="避免伪共享"></a>避免伪共享</h5><p>对于如下结构体</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">test</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">int</span> b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>该结构体中成员变量在物理内存地址上是连续的，很可能会与一个Cache Line，用宏定义将b的地址设为Cache Line对齐地址。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">test</span>&#123;</span></span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">int</span> b__cacheline_aligned_in_smp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>这样a和b就不会出现在一个Cache Line了，避免 Cache 伪共享实际上是用空间换时间的思想，浪费一部分 Cache 空间，从而换来性能的提升。</p>
<p>Java并发框架Disruptor 使用<strong>「字节填充 + 继承」</strong>的方式，来避免伪共享的问题。</p>
<p>Disruptor 中有一个 <strong>RingBuffer</strong> 类会经常被多个线程使用 ， RingBuffer 类里 7 个 long 类型的变量，CPU Cache 从内存读取数据的单位是 CPU Line，一般 64 位 CPU 的 CPU Line 的大小是 64 个字节，一个 long 类型的数据是 8 个字节，所以 CPU 一下会加载 8 个 long 类型的数据。</p>


<p>根据 JVM 对象继承关系中父类成员和子类成员，内存地址是连续排列布局的，因此 RingBufferPad 中的 7 个 long 类型数据作为 Cache Line <strong>前置填充</strong>，而 RingBuffer 中的 7 个 long 类型数据则作为 Cache Line <strong>后置填充</strong>，这 14 个 long 变量没有任何实际用途，更不会对它们进行读写操作。</p>


<p>另外，RingBufferFelds 里面定义的这些变量都是 <code>final</code> 修饰的，意味着第一次加载之后不会再修改， 又<strong>由于「前后」各填充了 7 个不会被读写的 long 类型变量，所以无论怎么加载 Cache Line，这整个 Cache Line 里都没有会发生更新操作的数据，于是只要数据被频繁地读取访问，就自然没有数据被换出 Cache 的可能，也因此不会产生伪共享的问题</strong>。</p>
<h4 id="CPU如何选择当前要执行的线程"><a href="#CPU如何选择当前要执行的线程" class="headerlink" title="CPU如何选择当前要执行的线程"></a>CPU如何选择当前要执行的线程</h4><p>在 Linux 内核中，进程和线程都是用 <code>task_struct</code> 结构体表示的，线程的 task_struct 相比进程的 task_struct 承载的 资源较少，也被称为轻量级进程。</p>
<p>Linux 内核里的调度器，调度的对象就是 <code>task_struct</code>，接下来我们就把这个数据结构统称为<strong>任务</strong>。</p>
<p>在 Linux 系统中，根据任务的优先级以及响应要求，主要分为两种，其中优先级的数值越小，优先级越高：</p>
<ul>
<li>实时任务，对系统的响应时间要求很高，优先级在 <code>0~99</code> 范围内的就算实时任务；</li>
<li>普通任务，响应时间没有很高的要求，优先级在 <code>100~139</code> 范围内都是普通任务级别；</li>
</ul>
<h5 id="调度类"><a href="#调度类" class="headerlink" title="调度类"></a>调度类</h5>

<p>Deadline 和 Realtime 这两个调度类，都应用于实时任务</p>
<ul>
<li><p><em>SCHED_DEADLINE</em>：是按照 deadline 进行调度的，距离当前时间点最近的 deadline 的任务会被优先调度；</p>
</li>
<li><p><em>SCHED_FIFO</em>：同优先级任务先来先服务，高优先级的可插队</p>
</li>
<li><p><em>SCHED_RR</em>：对于相同优先级的任务，轮流着运行，每个任务都有一定的时间片，当用完时间片的任务会被放到队列尾部，以保证相同优先级任务的公平性，高优先级可插队</p>
</li>
</ul>
<p>Fair 调度类是应用于普通任务，都是由 CFS 调度器管理的，分为两种调度策略：</p>
<ul>
<li><em>SCHED_NORMAL</em>：普通任务使用的调度策略；</li>
<li><em>SCHED_BATCH</em>：后台任务的调度策略，不和终端进行交互，因此在不影响其他需要交互的任务，可以适当降低它的优先级。</li>
</ul>
<h5 id="完全公平调度"><a href="#完全公平调度" class="headerlink" title="完全公平调度"></a>完全公平调度</h5><p>平日里遇到的基本都是普通任务，对于普通任务来说，公平性最重要。</p>
<p>在 Linux 里面，实现了一个基于 CFS 的调度算法，也就是<strong>完全公平调度（Completely Fair Scheduling）</strong>。理念是想让分配给每个任务的 CPU 时间是一样，于是<strong>它为每个任务安排一个虚拟运行时间 vruntime，如果一个任务在运行，运行的越久vruntime 就会越大，没有被运行的任务，vruntime 不变</strong>。<strong>在 CFS 算法调度的时候，会优先选择 vruntime 少的任务</strong>，以保证每个任务的公平性。</p>
<p>但普通任务也有优先级，所以在计算vruntime 还要考虑普通任务的<strong>权重值</strong>，注意权重值并不是优先级的值，内核中会有一个 nice 级别与权重值的转换表，nice 级别越低的权重值就越大。<strong>在「同样的实际运行时间」里，高权重任务的 vruntime 比低权重任务的 vruntime</strong> <strong>少</strong>，所以高权重的任务就会被优先调度了，获得的实际运行时间就多。</p>
<h5 id="CPU运行队列"><a href="#CPU运行队列" class="headerlink" title="CPU运行队列"></a>CPU运行队列</h5><p>一个系统通常都会运行着很多任务，多任务的数量基本都是远超 CPU 核心数量，因此这时候就需要<strong>排队</strong>。</p>
<p>每个 CPU 都有自己的<strong>运行队列（Run Queue, rq）</strong>，用于描述在此 CPU 上所运行的所有进程，其队列包含三个运行队列，<strong>Deadline 运行队列</strong> dl_rq、<strong>实时任务运行队列</strong> rt_rq 和 <strong>CFS 运行队列</strong> csf_rq，其中 csf_rq 是用红黑树来描述的，按 vruntime 大小来排序的，<strong>最左侧的叶子节点，就是下次会被调度的任务</strong>。</p>


<p>优先级如下：Deadline &gt; Realtime &gt; Fair，这意味着 Linux 选择下一个任务执行的时候，会按照此优先级顺序进行选择，也就是说先从 <code>dl_rq</code> 里选择任务，然后从 <code>rt_rq</code> 里选择任务，最后从 <code>csf_rq</code> 里选择任务。因此，<strong>实时任务总是会比普通任务优先被执行</strong>。</p>
<h5 id="调整优先级"><a href="#调整优先级" class="headerlink" title="调整优先级"></a>调整优先级</h5><p>启动任务的时候，没有特意去指定优先级的话，默认情况下都是普通任务。<strong>如果你想让某个普通任务有更多的执行时间，可以调整任务的 <code>nice</code> 值</strong>（注意nice是调普通任务的），从而让优先级高一些的任务执行更多时间。nice 的值能设置的范围是 <code>-20～19</code>， 值越低，表明优先级越高，因此 -20 是最高优先级，19 则是最低优先级，默认优先级是 0。</p>
<h3 id="软中断"><a href="#软中断" class="headerlink" title="#软中断"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/1_hardware/soft_interrupt.html#_2-6-%E4%BB%80%E4%B9%88%E6%98%AF%E8%BD%AF%E4%B8%AD%E6%96%AD">#</a>软中断</h3><h3 id="为什么-0-1-0-2-不等于-0-3-？（很值得学习）"><a href="#为什么-0-1-0-2-不等于-0-3-？（很值得学习）" class="headerlink" title="#为什么 0.1 + 0.2 不等于 0.3 ？（很值得学习）"></a><a target="_blank" rel="noopener" href="https://xiaolincoding.com/os/1_hardware/float.html#_2-7-%E4%B8%BA%E4%BB%80%E4%B9%88-0-1-0-2-%E4%B8%8D%E7%AD%89%E4%BA%8E-0-3">#</a>为什么 0.1 + 0.2 不等于 0.3 ？（很值得学习）</h3><h2 id="操作系统结构"><a href="#操作系统结构" class="headerlink" title="操作系统结构"></a>操作系统结构</h2><h3 id="内核"><a href="#内核" class="headerlink" title="内核"></a>内核</h3><p>如果每个应用都要和硬件设备对接通信协议，那这样太累了，所以这个中间人就由内核来负责，<strong>让内核作为应用连接硬件设备的桥梁</strong>，应用程序只需关心与内核交互，不用关心硬件的细节。</p>


<p>内核的基本能力：</p>
<ul>
<li>管理进程、线程，决定哪个进程、线程使用 CPU</li>
<li>管理内存，决定内存的分配和回收</li>
<li>管理硬件设备，为进程与硬件设备之间提供通信能力</li>
<li>提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。</li>
</ul>
<p>内核是怎么工作的？</p>
<p>内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域：</p>
<ul>
<li>内核空间，这个内存空间只有内核程序可以访问；</li>
<li>用户空间，这个内存空间专门给应用程序使用；</li>
</ul>
<p>用户空间的代码只能访问一个局部的内存空间，而内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，我们常说该程序在<strong>用户态</strong>执行，而当程序使内核空间时，程序则在<strong>内核态</strong>执行。</p>
<p>内核程序执行在内核态，用户程序执行在用户态。</p>


<p>当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。</p>
<h3 id="Linux-内核的设计理念"><a href="#Linux-内核的设计理念" class="headerlink" title="Linux 内核的设计理念"></a>Linux 内核的设计理念</h3><ol>
<li>MutiTask 的意思是<strong>多任务</strong>，代表着 Linux 是一个多任务的操作系统。多任务意味着可以有多个任务同时执行，并发或并行：</li>
</ol>
<ul>
<li>对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为<strong>并发</strong>。</li>
<li>对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为<strong>并行</strong>。</li>
</ul>
<ol start="2">
<li>SMP 的意思是<strong>对称多处理</strong>，<strong>代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。</strong>这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。</li>
<li>ELF可执行文件链接格式，是 Linux 操作系统中可执行文件的存储格式</li>
<li>宏内核</li>
</ol>
<h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>单片机没有操作系统，所以每次写完代码，都需要借助工具把程序烧录进去，程序才能跑起来。<strong>单片机的 CPU 是直接操作内存的「物理地址」</strong>。</p>


<p>在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的。</p>
<p><strong>操作系统是如何解决这个问题呢？</strong></p>
<p>这里关键的问题是<strong>这两个程序都引用了绝对物理地址，而这正是我们最需要避免的</strong>。</p>
<p>我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「<strong>虚拟地址</strong>」，人人都有，大家自己玩自己的地址就行，互不干涉。但是<strong>有个前提每个进程都不能访问物理地址</strong>，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。</p>
<p><strong>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。</strong></p>
<p>如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。</p>
<p>这里就引出了两种地址的概念：</p>
<ul>
<li>我们程序所使用的内存地址叫做<strong>虚拟内存地址</strong>（<em>Virtual Memory Address</em>）</li>
<li>实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（<em>Physical Memory Address</em>）。</li>
</ul>
<p>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示（虚拟地址寻址）：</p>


<p><strong>操作系统是如何管理虚拟地址与物理地址之间的关系？</strong></p>
<p>主要有两种方式，分别是<strong>内存分段和内存分页</strong></p>
<h3 id="内存分段"><a href="#内存分段" class="headerlink" title="内存分段"></a>内存分段</h3><p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。<strong>不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。</strong></p>
<p><strong>分段机制下，虚拟地址和物理地址是如何映射的？</strong></p>
<p>分段机制下的虚拟地址由两部分组成，<strong>段选择子</strong>和<strong>段内偏移量</strong>。下图为内存分段-寻址方式</p>


<ul>
<li><strong>段选择子</strong>就保存在段寄存器里面。段选择子里面最重要的是<strong>段号</strong>，用作段表的索引。<strong>段表</strong>里面保存的是这个<strong>段的基地址、段的界限和特权等级</strong>等。</li>
<li>虚拟地址中的<strong>段内偏移量</strong>应该位于 0 和段界限之间，如果段内偏移量是合法的，就<strong>将段基地址+段内偏移量&#x3D;物理内存地址</strong>。</li>
</ul>
<p>在上面了，知道了虚拟地址是通过<strong>段表</strong>与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：</p>


<p>如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出<strong>物理地址 &#x3D; 段 3 基地址 7000 + 偏移量 500 &#x3D; 7500。</strong></p>
<p>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：</p>
<ul>
<li>第一个就是<strong>内存碎片</strong>的问题。</li>
<li>第二个就是<strong>内存交换的效率低</strong>的问题。</li>
</ul>
<p><strong>分段为什么会产生内存碎片的问题？</strong></p>
<p>假设有 1G 的物理内存，用户执行了多个程序，其中：</p>
<ul>
<li>游戏占用了 512MB 内存</li>
<li>浏览器占用了 128MB 内存</li>
<li>音乐占用了 256 MB 内存。</li>
</ul>
<p>这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 &#x3D; 256MB。</p>
<p>如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。</p>


<p>这里的内存碎片的问题共有两处地方：</p>
<ul>
<li>外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；</li>
<li>内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；</li>
</ul>
<p>针对上面两种内存碎片的问题，解决的方式会有所不同。</p>
<p>解决外部内存碎片的问题就是<strong>内存交换</strong>。</p>
<p>可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。</p>
<p><strong>这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。</strong></p>
<p><strong>分段为什么会导致内存交换效率低的问题？</strong></p>
<p>对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 <code>Swap</code> 内存区域，这个过程会产生性能瓶颈。</p>
<p>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。</p>
<p>所以，<strong>如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。</strong></p>
<p>为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了内存分页。</p>
<h3 id="内存分页"><a href="#内存分页" class="headerlink" title="内存分页"></a>内存分页</h3><p>分段的好处就是能产生连续的内存空间，但是会出现内存碎片和内存交换的空间太大的问题。要解决这些问题，就要少出现内存碎片。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是<strong>内存分页</strong>（<em>Paging</em>）。</p>
<p><strong>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小</strong>。这样一个连续并且尺寸固定的内存空间，<strong>页</strong>（<em>Page</em>）。在 Linux 下，每一页的大小为 <code>4KB</code>。</p>
<p>虚拟地址与物理地址之间通过<strong>页表</strong>来映射，如下图：</p>


<p>页表是存储在内存里的，<strong>内存管理单元</strong> （<em>MMU</em>）将虚拟内存地址转换成物理地址的工作。</p>
<p>当进程访问的虚拟地址在页表中查不到时，系统会产生一个<strong>缺页异常</strong>，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</p>
<h5 id="分页是怎么解决分段的内存碎片、内存交换效率低的问题？"><a href="#分页是怎么解决分段的内存碎片、内存交换效率低的问题？" class="headerlink" title="分页是怎么解决分段的内存碎片、内存交换效率低的问题？"></a>分页是怎么解决分段的内存碎片、内存交换效率低的问题？</h5><p>1.由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而<strong>采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。</strong></p>
<p>分段是需要一片连续的内存，如果此时内存只有一个10MB连续的内存，那么如果有个需要20MB内存大小的程序要执行，那么就会执行失败，此时这连续10MB就相当于是一个内存碎片（外部内存碎片）。<strong>但是分片就不一样的，内存不一定要连续的，只要内存有20MB的空间，也就是有20MB&#x2F;4KB个分片的话，就可以运行这个程序，就不存在外部内存碎片的问题了。</strong>当然分片的话内部内存碎片还是存在的，比如明明只需要一个1kb的内存，但是还是划分了4kb的内存。</p>
<p>2.如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为<strong>换出</strong>（<em>Swap Out</em>）。一旦需要的时候，再加载进来，称为<strong>换入</strong>（<em>Swap In</em>）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，<strong>内存交换的效率就相对比较高。</strong></p>
<p>3.分页的方式在加载程序的时候，<strong>不再需要一次性都把程序加载到物理内存中</strong>。可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是<strong>只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。</strong></p>
<h5 id="分页机制下，虚拟地址和物理地址是如何映射的？"><a href="#分页机制下，虚拟地址和物理地址是如何映射的？" class="headerlink" title="分页机制下，虚拟地址和物理地址是如何映射的？**"></a>分页机制下，虚拟地址和物理地址是如何映射的？**</h5><p>在分页机制下，虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，<strong>页表</strong>包含物理页每页所在<strong>物理内存的基地址</strong>，这个<strong>基地址与页内偏移的组合就形成了物理内存地址</strong>，见下图。</p>


<p>对于一个内存地址转换，其实就是这样三个步骤：</p>
<ul>
<li>把虚拟内存地址，切分成页号和偏移量；</li>
<li>根据页号，从页表里面，查询对应的物理页号；</li>
<li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li>
</ul>
<p><strong>简单的分页有什么缺陷吗？</strong></p>
<p>有空间上的缺陷。</p>
<p>因为操作系统是可以同时运行非常多的进程的，那这不就意味着页表会非常的庞大。</p>
<p>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就需要大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 <code>4MB</code> （4B*2^20）的内存来存储页表。</p>
<p>每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。<code>100</code> 个进程的话，就需要 <code>400MB</code> 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。</p>
<h5 id="多级页表用于解决上述问题"><a href="#多级页表用于解决上述问题" class="headerlink" title="多级页表用于解决上述问题"></a>多级页表用于解决上述问题</h5><p>将上述2^20个页表项的单级页表（一级页表）再分页，分成1024个二级页表,每个二级页表包含1024个页表项，形成<strong>二级分页</strong></p>


<h5 id="分了二级表，映射-4GB-地址空间就需要-4KB（一级页表）-4MB（二级页表）的内存，这样占用空间不是更大了吗？"><a href="#分了二级表，映射-4GB-地址空间就需要-4KB（一级页表）-4MB（二级页表）的内存，这样占用空间不是更大了吗？" class="headerlink" title="分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？"></a>分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？</h5><p>如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但我们往往不会为一个进程分配那么多内存。</p>
<p>每个进程都有 4GB 的虚拟地址空间，但大多数程序使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，<strong>对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。</strong></p>
<p>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但<strong>如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表</strong>。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）&#x3D; <code>0.804MB</code>，这对比单级页表的 <code>4MB</code> 是不是一个巨大的节约？</p>
<p>为什么不分级的页表就做不到这样节约内存呢？</p>
<p>我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以<strong>页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项</strong>（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。</p>
<p>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录</p>
<h5 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h5><p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，降低了这俩地址转换的速度。</p>
<p>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。</p>


<p>在 CPU 芯片里面，封装了内存管理单元MMU芯片，它用来完成地址转换和 TLB 的访问与交互。</p>
<p>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。</p>
<p>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。</p>
<h4 id="段页式内存管理"><a href="#段页式内存管理" class="headerlink" title="段页式内存管理"></a>段页式内存管理</h4><p>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为<strong>段页式内存管理</strong>。</p>
<p>段页式地址变换中要得到物理地址须经过三次内存访问：</p>
<ul>
<li>第一次访问段表，得到页表起始地址；</li>
<li>第二次访问页表，得到物理页号；</li>
<li>第三次将物理页号与页内位移组合，得到物理地址。</li>
</ul>
<h3 id="Linux内存管理"><a href="#Linux内存管理" class="headerlink" title="Linux内存管理"></a>Linux内存管理</h3><p><strong>Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制</strong>。因为 Intel X86 CPU 一律对程序中使用的地址先进行段式映射，然后才能进行页式映射。既然 CPU 的硬件结构是这样，Linux 内核也只好服从 Intel 的选择。</p>
<p><strong>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护。</strong></p>
<h4 id="Linux-的虚拟地址空间是如何分布的？"><a href="#Linux-的虚拟地址空间是如何分布的？" class="headerlink" title="Linux 的虚拟地址空间是如何分布的？"></a>Linux 的虚拟地址空间是如何分布的？</h4><p>在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分，不同位数的系统，地址空间的范围也不同。</p>


<p>内核空间与用户空间的区别：</p>
<ul>
<li>进程在用户态时，只能访问用户空间内存；</li>
<li>只有进入内核态后，才可以访问内核空间的内存；</li>
</ul>
<p>虽然每个进程都各自有独立的虚拟内存，但是<strong>每个虚拟内存中的内核地址，其实关联的都是相同的物理内存</strong>。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p>


<p>用户空间分布的情况，以 32 位系统为例</p>


<ul>
<li>程序文件段（.text），包括二进制可执行代码；</li>
<li>已初始化数据段（.data），包括静态常量；</li>
<li>未初始化数据段（.bss），包括未初始化的静态变量；</li>
<li>堆段，包括动态分配的内存，从低地址开始向上增长；</li>
<li>文件映射段，包括动态库、共享内存等，从低地址开始向上增长（<a target="_blank" rel="noopener" href="http://lishiwen4.github.io/linux/linux-process-memory-location">跟硬件和内核版本有关 (opens new window)</a>）；</li>
<li>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 <code>8 MB</code>。当然系统也提供了参数，以便我们自定义大小；</li>
</ul>
<p>在这6个内存段中，<strong>堆和文件映射段的内存是动态分配的</strong>。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套<strong>虚拟地址空间</strong>，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。</p>
<p>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过<strong>内存交换</strong>技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。</p>
<p>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。</p>
<p>那么对于虚拟地址与物理地址的映射关系，可以有<strong>分段</strong>和<strong>分页</strong>的方式，同时两者结合都是可以的。</p>
<p>内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致内存碎片和内存交换效率低的问题。</p>
<p>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 <code>4KB</code>。由于分了页后，就不会产生细小的内存碎片。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。</p>
<p>再来，为了解决简单分页产生的页表过大的问题，就有了<strong>多级页表</strong>，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的<strong>局部性原理</strong>，在 CPU 芯片中加入了 <strong>TLB</strong>，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。</p>
<p><strong>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理</strong>。于是 Linux 就把所有段的基地址设为 <code>0</code>，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。</p>
<p>另外，Linux 系统中虚拟空间分布可分为<strong>用户态</strong>和<strong>内核态</strong>两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。</p>
<h3 id="内存满了，会发生什么"><a href="#内存满了，会发生什么" class="headerlink" title="内存满了，会发生什么"></a>内存满了，会发生什么</h3><p>虚拟内存的作用：</p>
<ul>
<li>由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的。这就解决了多进程之间地址冲突的问题。</li>
<li>页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。</li>
</ul>
<h4 id="内存分配过程"><a href="#内存分配过程" class="headerlink" title="内存分配过程"></a>内存分配过程</h4><p>楼仔</p>
<h2 id="操作系统的功能"><a href="#操作系统的功能" class="headerlink" title="操作系统的功能"></a>操作系统的功能</h2><p>操作系统位于硬件资源之上，管理硬件资源; 应⽤程序之下，为应⽤程序提供服务，同时管理应⽤程序</p>
<h2 id="进程间通信-IPC"><a href="#进程间通信-IPC" class="headerlink" title="进程间通信(IPC)"></a>进程间通信(IPC)</h2><p>Linux下常见的&#x3D;&#x3D;五种进程间通信机制：管道 命名管道 消息队列 共享内存 信号量&#x3D;&#x3D;</p>
<h3 id="为什么需要IPC"><a href="#为什么需要IPC" class="headerlink" title="为什么需要IPC"></a>为什么需要IPC</h3><p>数据传输：一个进程将他的数据发给另一进程</p>
<p>资源共享：多进程间共享同样的资源</p>
<p>通知事件：一个进程需要向另一个或一组进程发消息，告诉它们发生了某种事件</p>
<p>进程控制：有些进程希望完全控制另一进程的执行，如debug进程，该控制进程希望能拦截另一个进程的所有操作，并能及时知道他的状态改变。</p>
<h3 id="IPC原理"><a href="#IPC原理" class="headerlink" title="IPC原理"></a>IPC原理</h3>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/06/21/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" rel="prev" title="计算机网络">
      <i class="fa fa-chevron-left"></i> 计算机网络
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F"><span class="nav-number">1.</span> <span class="nav-text">操作系统</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84"><span class="nav-number">1.1.</span> <span class="nav-text">硬件结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98"><span class="nav-number">1.1.1.</span> <span class="nav-text">内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU"><span class="nav-number">1.1.2.</span> <span class="nav-text">CPU</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BA%BF"><span class="nav-number">1.1.3.</span> <span class="nav-text">总线</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E8%B7%AF%E4%BD%8D%E5%AE%BD%E5%92%8CCPU%E4%BD%8D%E5%AE%BD"><span class="nav-number">1.1.4.</span> <span class="nav-text">线路位宽和CPU位宽</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%87%E7%A8%8B"><span class="nav-number">1.1.5.</span> <span class="nav-text">程序执行的基本过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#a-x3D-1-2%E6%89%A7%E8%A1%8C%E7%9A%84%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"><span class="nav-number">1.1.6.</span> <span class="nav-text">a &#x3D; 1+2执行的具体过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%87%E4%BB%A4%E2%80%A6"><span class="nav-number">1.1.7.</span> <span class="nav-text">指令…</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8C%87%E4%BB%A4%E6%89%A7%E8%A1%8C%E9%80%9F%E5%BA%A6"><span class="nav-number">1.1.8.</span> <span class="nav-text">指令执行速度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%A8%8B%E5%BA%8F%E7%9A%84CPU%E6%89%A7%E8%A1%8C%E6%97%B6%E9%97%B4"><span class="nav-number">1.1.9.</span> <span class="nav-text">程序的CPU执行时间</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98"><span class="nav-number">1.1.10.</span> <span class="nav-text">几个问题</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.2.</span> <span class="nav-text"></span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E5%99%A8"><span class="nav-number">1.2.1.</span> <span class="nav-text">存储器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AF%84%E5%AD%98%E5%99%A8"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">寄存器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU-Cache"><span class="nav-number">1.2.1.2.</span> <span class="nav-text">CPU Cache</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%85%E5%AD%98-1"><span class="nav-number">1.2.1.3.</span> <span class="nav-text">内存</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SSD-x2F-HDD-%E7%A1%AC%E7%9B%98"><span class="nav-number">1.2.1.4.</span> <span class="nav-text">SSD&#x2F;HDD 硬盘</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E5%85%B3%E7%B3%BB"><span class="nav-number">1.2.1.5.</span> <span class="nav-text">存储器层次关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E8%AE%A9CPU%E8%B7%91%E7%9A%84%E6%9B%B4%E5%BF%AB%E7%9A%84%E4%BB%A3%E7%A0%81"><span class="nav-number">1.2.2.</span> <span class="nav-text">如何写出让CPU跑的更快的代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E8%AF%BB%E5%8F%96%E8%BF%87%E7%A8%8B"><span class="nav-number">1.2.3.</span> <span class="nav-text">CPU Cache的数据结构和读取过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E5%88%B0%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA%E8%B7%91%E7%9A%84%E6%9B%B4%E5%BF%AB%E7%9A%84%E4%BB%A3%E7%A0%81-x2F-%E5%A6%82%E4%BD%95%E5%86%99%E5%87%BA-CPU-%E7%BC%93%E5%AD%98%E5%91%BD%E4%B8%AD%E7%8E%87%E9%AB%98%E7%9A%84%E4%BB%A3%E7%A0%81%EF%BC%9F"><span class="nav-number">1.2.4.</span> <span class="nav-text">回到如何写出跑的更快的代码&#x2F;如何写出 CPU 缓存命中率高的代码？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A0%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E7%9A%84%E5%91%BD%E4%B8%AD%E7%8E%87%EF%BC%9F"><span class="nav-number">1.2.4.1.</span> <span class="nav-text">①如何提升数据缓存的命中率？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A1%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E6%8C%87%E4%BB%A4%E7%BC%93%E5%AD%98%E7%9A%84%E5%91%BD%E4%B8%AD%E7%8E%87%EF%BC%9F"><span class="nav-number">1.2.4.2.</span> <span class="nav-text">②如何提升指令缓存的命中率？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E2%91%A2%E6%8F%90%E5%8D%87%E5%A4%9A%E6%A0%B8CPU%E7%BC%93%E5%AD%98%E5%91%BD%E4%B8%AD%E7%8E%87"><span class="nav-number">1.2.4.3.</span> <span class="nav-text">③提升多核CPU缓存命中率</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E2%80%A6"><span class="nav-number">1.2.5.</span> <span class="nav-text">CPU缓存一致性…</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E7%9A%84"><span class="nav-number">1.2.6.</span> <span class="nav-text">CPU如何执行任务的</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE"><span class="nav-number">1.2.6.1.</span> <span class="nav-text">CPU如何读写数据</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BC%AA%E5%85%B1%E4%BA%AB"><span class="nav-number">1.2.6.1.1.</span> <span class="nav-text">伪共享</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E9%81%BF%E5%85%8D%E4%BC%AA%E5%85%B1%E4%BA%AB"><span class="nav-number">1.2.6.1.2.</span> <span class="nav-text">避免伪共享</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CPU%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%BD%93%E5%89%8D%E8%A6%81%E6%89%A7%E8%A1%8C%E7%9A%84%E7%BA%BF%E7%A8%8B"><span class="nav-number">1.2.6.2.</span> <span class="nav-text">CPU如何选择当前要执行的线程</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B0%83%E5%BA%A6%E7%B1%BB"><span class="nav-number">1.2.6.2.1.</span> <span class="nav-text">调度类</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6"><span class="nav-number">1.2.6.2.2.</span> <span class="nav-text">完全公平调度</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#CPU%E8%BF%90%E8%A1%8C%E9%98%9F%E5%88%97"><span class="nav-number">1.2.6.2.3.</span> <span class="nav-text">CPU运行队列</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E8%B0%83%E6%95%B4%E4%BC%98%E5%85%88%E7%BA%A7"><span class="nav-number">1.2.6.2.4.</span> <span class="nav-text">调整优先级</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BD%AF%E4%B8%AD%E6%96%AD"><span class="nav-number">1.2.7.</span> <span class="nav-text">软中断</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-0-1-0-2-%E4%B8%8D%E7%AD%89%E4%BA%8E-0-3-%EF%BC%9F%EF%BC%88%E5%BE%88%E5%80%BC%E5%BE%97%E5%AD%A6%E4%B9%A0%EF%BC%89"><span class="nav-number">1.2.8.</span> <span class="nav-text">为什么 0.1 + 0.2 不等于 0.3 ？（很值得学习）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84"><span class="nav-number">1.3.</span> <span class="nav-text">操作系统结构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E6%A0%B8"><span class="nav-number">1.3.1.</span> <span class="nav-text">内核</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux-%E5%86%85%E6%A0%B8%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5"><span class="nav-number">1.3.2.</span> <span class="nav-text">Linux 内核的设计理念</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-number">1.4.</span> <span class="nav-text">内存管理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98"><span class="nav-number">1.4.1.</span> <span class="nav-text">虚拟内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E5%88%86%E6%AE%B5"><span class="nav-number">1.4.2.</span> <span class="nav-text">内存分段</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E5%88%86%E9%A1%B5"><span class="nav-number">1.4.3.</span> <span class="nav-text">内存分页</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E9%A1%B5%E6%98%AF%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E5%88%86%E6%AE%B5%E7%9A%84%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E3%80%81%E5%86%85%E5%AD%98%E4%BA%A4%E6%8D%A2%E6%95%88%E7%8E%87%E4%BD%8E%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="nav-number">1.4.3.0.1.</span> <span class="nav-text">分页是怎么解决分段的内存碎片、内存交换效率低的问题？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%E4%B8%8B%EF%BC%8C%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E5%92%8C%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80%E6%98%AF%E5%A6%82%E4%BD%95%E6%98%A0%E5%B0%84%E7%9A%84%EF%BC%9F"><span class="nav-number">1.4.3.0.2.</span> <span class="nav-text">分页机制下，虚拟地址和物理地址是如何映射的？**</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8%E7%94%A8%E4%BA%8E%E8%A7%A3%E5%86%B3%E4%B8%8A%E8%BF%B0%E9%97%AE%E9%A2%98"><span class="nav-number">1.4.3.0.3.</span> <span class="nav-text">多级页表用于解决上述问题</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%88%86%E4%BA%86%E4%BA%8C%E7%BA%A7%E8%A1%A8%EF%BC%8C%E6%98%A0%E5%B0%84-4GB-%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%B0%B1%E9%9C%80%E8%A6%81-4KB%EF%BC%88%E4%B8%80%E7%BA%A7%E9%A1%B5%E8%A1%A8%EF%BC%89-4MB%EF%BC%88%E4%BA%8C%E7%BA%A7%E9%A1%B5%E8%A1%A8%EF%BC%89%E7%9A%84%E5%86%85%E5%AD%98%EF%BC%8C%E8%BF%99%E6%A0%B7%E5%8D%A0%E7%94%A8%E7%A9%BA%E9%97%B4%E4%B8%8D%E6%98%AF%E6%9B%B4%E5%A4%A7%E4%BA%86%E5%90%97%EF%BC%9F"><span class="nav-number">1.4.3.0.4.</span> <span class="nav-text">分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#TLB"><span class="nav-number">1.4.3.0.5.</span> <span class="nav-text">TLB</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AE%B5%E9%A1%B5%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">段页式内存管理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linux%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="nav-number">1.4.4.</span> <span class="nav-text">Linux内存管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Linux-%E7%9A%84%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E6%98%AF%E5%A6%82%E4%BD%95%E5%88%86%E5%B8%83%E7%9A%84%EF%BC%9F"><span class="nav-number">1.4.4.1.</span> <span class="nav-text">Linux 的虚拟地址空间是如何分布的？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">1.4.5.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E6%BB%A1%E4%BA%86%EF%BC%8C%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88"><span class="nav-number">1.4.6.</span> <span class="nav-text">内存满了，会发生什么</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E8%BF%87%E7%A8%8B"><span class="nav-number">1.4.6.1.</span> <span class="nav-text">内存分配过程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8A%9F%E8%83%BD"><span class="nav-number">1.5.</span> <span class="nav-text">操作系统的功能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-IPC"><span class="nav-number">1.6.</span> <span class="nav-text">进程间通信(IPC)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81IPC"><span class="nav-number">1.6.1.</span> <span class="nav-text">为什么需要IPC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IPC%E5%8E%9F%E7%90%86"><span class="nav-number">1.6.2.</span> <span class="nav-text">IPC原理</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
